{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fachruzaini/lazada-id-reviews/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the main directory\n",
    "# So, it's executed from main directory\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.env') as f:\n",
    "    os.environ.update(\n",
    "        line.strip().split('=') for line in f\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fachruzaini/lazada-id-reviews'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Testing Config\n",
    "\n",
    "This code will be apply in `src/LadazaIDReview/entity/config_entity.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class UnitTestConfig:\n",
    "    root_dir: Path\n",
    "    mlflow_tracking_uri: str\n",
    "    mlflow_model_name: str\n",
    "    mlflow_deploy_model_alias: str\n",
    "    mlflow_input_example_path: Path\n",
    "    app_endpoint: str\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Testing Config Manager\n",
    "\n",
    "This code will be apply in `src/LazadaIDReview/config/configurations.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LazadaIDReviews.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from LazadaIDReviews.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_filepath = CONFIG_FILE_PATH,\n",
    "                 params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_unit_test_config(self) -> UnitTestConfig:\n",
    "        \"\"\"read training evaluation config file and store as \n",
    "        config entity then apply the dataclasses\n",
    "        \n",
    "        Returns:\n",
    "            config: UnitTestConfig type\n",
    "        \"\"\"\n",
    "        predict_config = self.config.predict\n",
    "        unit_test_config = self.config.unit_test\n",
    "\n",
    "        create_directories([unit_test_config.root_dir])\n",
    "\n",
    "        config = UnitTestConfig(\n",
    "            root_dir=unit_test_config.root_dir,\n",
    "            mlflow_tracking_uri=os.environ[\"MLFLOW_TRACKING_URI\"],\n",
    "            mlflow_model_name=predict_config.mlflow_model_name,\n",
    "            mlflow_deploy_model_alias=os.environ[\"MLFLOW_DEPLOY_MODEL_ALIAS\"],\n",
    "            mlflow_input_example_path=unit_test_config.mlflow_input_example_path,\n",
    "            app_endpoint=os.environ[\"APP_ENDPOINT\"]\n",
    "        )\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fachruzaini/lazada-id-reviews/.lazada-venv/lib/python3.12/site-packages/mlflow/utils/requirements_utils.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources  # noqa: TID251\n"
     ]
    }
   ],
   "source": [
    "from mlflow.artifacts import download_artifacts\n",
    "from mlflow import MlflowClient\n",
    "from mlflow import pyfunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Debug**: Explain when doing the preparation test in the notebook with MLflow like load input example and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-02 16:38:18,025: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-07-02 16:38:18,031: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2025-07-02 16:38:18,032: INFO: common: created directory at: artifacts]\n",
      "[2025-07-02 16:38:18,035: INFO: common: created directory at: artifacts/test]\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "unit_test_config = config.get_unit_test_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the deployed model from MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlflow-artifacts:/1/c9d5e14ac4384fc7a3fba18602467c69/artifacts/models'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MlflowClient(tracking_uri=unit_test_config.mlflow_tracking_uri)\n",
    "selected_model = client.get_model_version_by_alias(\n",
    "    unit_test_config.mlflow_model_name, \n",
    "    unit_test_config.mlflow_deploy_model_alias\n",
    ")\n",
    "\n",
    "selected_model.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b09791de41e4fafab7fbe9270f90550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: models\n",
       "  flavor: mlflow.sklearn\n",
       "  run_id: c9d5e14ac4384fc7a3fba18602467c69"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = pyfunc.load_model(model_uri=selected_model.source)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the model `run_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c9d5e14ac4384fc7a3fba18602467c69'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_run_id = selected_model.run_id\n",
    "selected_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210161f131db490ba6e055fd0bcf7b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/fachruzaini/lazada-id-reviews/artifacts/test/models/input_example.json'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_artifacts(\n",
    "    run_id=selected_run_id,\n",
    "    artifact_path=unit_test_config.mlflow_input_example_path,\n",
    "    dst_path=unit_test_config.root_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': ['reviewContents'],\n",
       " 'data': [[['barang sudah di terima dengan baik, dah di coba Oke.terima kasih Ladaza',\n",
       "    'sangat puas trimakasih lazada',\n",
       "    'D pasang ke SS J2 nggak bisa. Apa kartuny yg rusak?',\n",
       "    'rekomendet bgt lahh barang bagus cpt bgt sampe y padahal tmpat aq desa plosok bgt tpi cuman 2hri dah sampe',\n",
       "    'Film ato lagu2 saat d putar dri plashdisk error..smuanya filmku error gx bsa d putar😭😭😭',\n",
       "    'bagus',\n",
       "    'Toshiba 1 TB Hitam dengan banyak GRATIS Usb TOSHIBA 32GB + Pouch Harddisk & Usb OTG Reader Android NICE !!!!',\n",
       "    'Produk original dan awet',\n",
       "    'Barang bagus mulus wlau hnya paking buble warp, kulitas lumayan lh dgn harga sgitu.. Rekomended bgt ni brg..',\n",
       "    'mantabb, barang bagus sesuai pesanan dan datangnya cepat 👍👍']]]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "f = open(f\"{unit_test_config.root_dir}/{unit_test_config.mlflow_input_example_path}\")\n",
    "input_example = json.load(f)\n",
    "input_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the input data from MLflow input examples and try to match with the MLflow input example format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reviewContents': ['barang sudah di terima dengan baik, dah di coba Oke.terima kasih Ladaza',\n",
       "  'sangat puas trimakasih lazada',\n",
       "  'D pasang ke SS J2 nggak bisa. Apa kartuny yg rusak?',\n",
       "  'rekomendet bgt lahh barang bagus cpt bgt sampe y padahal tmpat aq desa plosok bgt tpi cuman 2hri dah sampe',\n",
       "  'Film ato lagu2 saat d putar dri plashdisk error..smuanya filmku error gx bsa d putar😭😭😭',\n",
       "  'bagus',\n",
       "  'Toshiba 1 TB Hitam dengan banyak GRATIS Usb TOSHIBA 32GB + Pouch Harddisk & Usb OTG Reader Android NICE !!!!',\n",
       "  'Produk original dan awet',\n",
       "  'Barang bagus mulus wlau hnya paking buble warp, kulitas lumayan lh dgn harga sgitu.. Rekomended bgt ni brg..',\n",
       "  'mantabb, barang bagus sesuai pesanan dan datangnya cepat 👍👍']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_body = {\n",
    "    input_example[\"columns\"][0]: input_example['data'][0][0]\n",
    "}\n",
    "\n",
    "request_body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the `app.py` with http request with MLflow input data example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "result = requests.post(url=unit_test_config.app_endpoint, json=request_body)\n",
    "y_predict = result.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 1, 5, 2, 5, 1, 5, 5, 5]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Unit Testing\n",
    "\n",
    "This code in `src/LazadaIDReview/components/unit_testing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "from LazadaIDReviews import logger\n",
    "\n",
    "class UnitTesting:\n",
    "    def __init__(self, config: UnitTestConfig):\n",
    "        self.config = config\n",
    "        self.req_body_key = None\n",
    "        self.req_body = None\n",
    "    \n",
    "    def set_request_body(self) -> None:\n",
    "        \"\"\"predict the data with linear regression model\n",
    "\n",
    "        Raises:\n",
    "            client_error: error when access mlflow to get deployed model\n",
    "            download_error: error when download vectorizer from mlflow artifact\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Set MLflow Client.\")\n",
    "            client = MlflowClient(tracking_uri=self.config.mlflow_tracking_uri)\n",
    "            selected_model = client.get_model_version_by_alias(\n",
    "                self.config.mlflow_model_name, \n",
    "                self.config.mlflow_deploy_model_alias\n",
    "            )\n",
    "            \n",
    "            logger.info(\"Get the deployed model run id.\")\n",
    "            selected_run_id = selected_model.run_id\n",
    "        except Exception as client_error:\n",
    "            logger.error(client_error)\n",
    "            raise client_error\n",
    "\n",
    "        try:\n",
    "            logger.info(\"Downloading vectorizer from MLflow's artifacts.\")\n",
    "            download_artifacts(\n",
    "                run_id=selected_run_id,\n",
    "                artifact_path=self.config.mlflow_input_example_path,\n",
    "                dst_path=self.config.root_dir\n",
    "            )\n",
    "        except Exception as download_error:\n",
    "            logger.error(download_error)\n",
    "            raise download_error\n",
    "        \n",
    "        logger.info(\"Open MLflow input example.\")\n",
    "        f = open(f\"{self.config.root_dir}/{self.config.mlflow_input_example_path}\")\n",
    "        input_example = json.load(f)\n",
    "\n",
    "        # handle mlflow input example data\n",
    "        data_key = input_example[\"columns\"][0]\n",
    "        data_val = input_example['data'][0][0]\n",
    "\n",
    "        # request params\n",
    "        self.req_body_key = data_key\n",
    "        self.req_body = {\n",
    "            data_key: data_val\n",
    "        }\n",
    "        \n",
    "    def get_request_body_value(self) -> list:\n",
    "        \"\"\"get the request body data\n",
    "\n",
    "        Returns:\n",
    "            req_body: list type\n",
    "        \"\"\"\n",
    "        logger.info(\"Get MLflow input example value.\")\n",
    "        req_body_value = self.req_body[self.req_body_key]\n",
    "        return req_body_value\n",
    "    \n",
    "    def get_output_length(self):\n",
    "        \"\"\"get the output length of the predict result\n",
    "\n",
    "        Returns:\n",
    "            len_result: list type\n",
    "        \"\"\"\n",
    "        logger.info(\"Get predicted result length.\")\n",
    "        result = requests.post(\n",
    "            url=self.config.app_endpoint, \n",
    "            json=self.req_body\n",
    "        )\n",
    "        len_result = len(result.json())\n",
    "        return len_result\n",
    "\n",
    "    def is_output_type_list(self) -> bool:\n",
    "        \"\"\"check if the output file is list data type\n",
    "\n",
    "        Returns:\n",
    "            is_list: bool type\n",
    "        \"\"\"\n",
    "        logger.info(\"Check is the predicted output is list.\")\n",
    "        result = requests.post(\n",
    "            url=self.config.app_endpoint, \n",
    "            json=self.req_body\n",
    "        )\n",
    "        is_list = type(result.json()) is list\n",
    "        return is_list\n",
    "\n",
    "    def is_output_type_consistent(self) -> bool:\n",
    "        \"\"\"check if the output file have consistent\n",
    "        data type inside a list\n",
    "\n",
    "        Returns:\n",
    "            bool type\n",
    "        \"\"\"\n",
    "        logger.info(\"Check is each predicted output is integer\")\n",
    "        result = requests.post(\n",
    "            url=self.config.app_endpoint, \n",
    "            json=self.req_body\n",
    "        )\n",
    "        for result in result.json():\n",
    "            if type(result) is not int:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Testing\n",
    "\n",
    "**Debug**: Simulate the unit testing without library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-02 16:38:24,162: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-07-02 16:38:24,165: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2025-07-02 16:38:24,167: INFO: common: created directory at: artifacts]\n",
      "[2025-07-02 16:38:24,170: INFO: common: created directory at: artifacts/test]\n",
      "[2025-07-02 16:38:24,173: INFO: 1595305458: Set MLflow Client.]\n",
      "[2025-07-02 16:38:24,195: INFO: 1595305458: Get the deployed model run id.]\n",
      "[2025-07-02 16:38:24,197: INFO: 1595305458: Downloading vectorizer from MLflow's artifacts.]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49020fb354c4e5c945517013cead0bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-02 16:38:24,307: INFO: 1595305458: Open MLflow input example.]\n",
      "Review Contents: \n",
      "[2025-07-02 16:38:24,310: INFO: 1595305458: Get MLflow input example value.]\n",
      "barang sudah di terima dengan baik, dah di coba Oke.terima kasih Ladaza\n",
      "sangat puas trimakasih lazada\n",
      "D pasang ke SS J2 nggak bisa. Apa kartuny yg rusak?\n",
      "rekomendet bgt lahh barang bagus cpt bgt sampe y padahal tmpat aq desa plosok bgt tpi cuman 2hri dah sampe\n",
      "Film ato lagu2 saat d putar dri plashdisk error..smuanya filmku error gx bsa d putar😭😭😭\n",
      "bagus\n",
      "Toshiba 1 TB Hitam dengan banyak GRATIS Usb TOSHIBA 32GB + Pouch Harddisk & Usb OTG Reader Android NICE !!!!\n",
      "Produk original dan awet\n",
      "Barang bagus mulus wlau hnya paking buble warp, kulitas lumayan lh dgn harga sgitu.. Rekomended bgt ni brg..\n",
      "mantabb, barang bagus sesuai pesanan dan datangnya cepat 👍👍\n",
      "\n",
      "Begin tests:\n",
      "[2025-07-02 16:38:24,314: INFO: 1595305458: Get predicted result length.]\n",
      "[2025-07-02 16:38:24,870: INFO: 1595305458: Get MLflow input example value.]\n",
      "Is same size: True\n",
      "[2025-07-02 16:38:24,872: INFO: 1595305458: Check is the predicted output is list.]\n",
      "Is the output is list: True\n",
      "[2025-07-02 16:38:25,391: INFO: 1595305458: Check is each predicted output is integer]\n",
      "Is the output consistent: True\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    unit_testing_config = config.get_unit_test_config()\n",
    "    unit_test = UnitTesting(config=unit_testing_config)\n",
    "    unit_test.set_request_body()\n",
    "    \n",
    "    print(\"Review Contents: \")\n",
    "    for content in unit_test.get_request_body_value():\n",
    "        print(content)\n",
    "    \n",
    "    print(\"\\nBegin tests:\")\n",
    "    print(f\"Is same size: {unit_test.get_output_length() == len(unit_test.get_request_body_value())}\")\n",
    "    print(f\"Is the output is list: {unit_test.is_output_type_list() == True}\")\n",
    "    print(f\"Is the output consistent: {unit_test.is_output_type_consistent() == True}\")\n",
    "except Exception as e:\n",
    "    logger.error(e)\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lazada-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
