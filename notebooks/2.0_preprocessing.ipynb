{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fachruzaini/lazada-id-reviews/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the main directory\n",
    "# So, it's executed from main directory\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fachruzaini/lazada-id-reviews'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing Config\n",
    "\n",
    "This code will be apply in `src/LadazaIDReview/entity/config_entity.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataDumpConfig:\n",
    "    root_dir: Path\n",
    "    reviews_path: Path\n",
    "    input_train_path: Path\n",
    "    input_test_path: Path\n",
    "    output_train_path: Path\n",
    "    output_test_path: Path\n",
    "    params_test_size: float\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataPreprocessingConfig:\n",
    "    root_dir: Path\n",
    "    input_train_path: Path\n",
    "    input_test_path: Path\n",
    "    vectorized_train_path: Path\n",
    "    vectorized_test_path: Path\n",
    "    model_dir: Path\n",
    "    vectorizer_model_path: Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing Config Manager\n",
    "\n",
    "This code will be apply in `src/LazadaIDReview/config/configurations.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we would do?\n",
    "+ Drop null values\n",
    "+ Splitting the dataset to train and test data\n",
    "+ Vectorize text using `TFIDF`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated before; let’s load, select columns, and drop null values from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LazadaIDReviews.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from LazadaIDReviews.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_filepath = CONFIG_FILE_PATH,\n",
    "                 params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_dump_data_config(self) -> DataDumpConfig:\n",
    "        \"\"\"read data dump config file and store as config entity\n",
    "        then apply the dataclasses\n",
    "        \n",
    "        Returns:\n",
    "            config: PreprocessingConfig type\n",
    "        \"\"\"\n",
    "        data_ingest_config = self.config.ingest_from_sql\n",
    "        data_dump_config = self.config.dump_data\n",
    "        dataset_params = self.params\n",
    "\n",
    "        create_directories([data_dump_config.root_dir])\n",
    "\n",
    "        config = DataDumpConfig(\n",
    "            root_dir=data_dump_config.root_dir,\n",
    "            reviews_path=data_ingest_config.reviews_path,\n",
    "            input_train_path=data_dump_config.input_train_path,\n",
    "            input_test_path=data_dump_config.input_test_path,\n",
    "            output_train_path=data_dump_config.output_train_path,\n",
    "            output_test_path=data_dump_config.output_test_path,\n",
    "            params_test_size=dataset_params.TEST_SIZE\n",
    "        )\n",
    "\n",
    "        return config\n",
    "    \n",
    "    def get_preprocessing_data_config(self) -> DataPreprocessingConfig:\n",
    "        \"\"\"read preprocessing config file and store as config entity\n",
    "        then apply the dataclasses\n",
    "        \n",
    "        Returns:\n",
    "            config: PreprocessingConfig type\n",
    "        \"\"\"\n",
    "        data_dump_config = self.config.dump_data\n",
    "        vectorize_config = self.config.vectorize_data\n",
    "        train_config = self.config.train_model\n",
    "\n",
    "        create_directories([vectorize_config.root_dir])\n",
    "\n",
    "        config = DataPreprocessingConfig(\n",
    "            root_dir=vectorize_config.root_dir,\n",
    "            input_train_path=Path(data_dump_config.input_train_path),\n",
    "            input_test_path=Path(data_dump_config.input_test_path),\n",
    "            vectorized_train_path=Path(vectorize_config.vectorized_train_path),\n",
    "            vectorized_test_path=Path(vectorize_config.vectorized_test_path),\n",
    "            model_dir=train_config.root_dir,\n",
    "            vectorizer_model_path=Path(vectorize_config.vectorizer_model_path)\n",
    "        )\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Preprocessing\n",
    "\n",
    "This code in `src/LazadaIDReview/components/preprocessing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from LazadaIDReviews import logger\n",
    "\n",
    "class DumpData:\n",
    "    def __init__(self, config: DataDumpConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def dump_data(self) -> None:\n",
    "        \"\"\"dump the splited dataset to data training and testing\n",
    "        \"\"\"\n",
    "        logger.info(f\"Read reviews file.\")\n",
    "        dataset_reviews = pd.read_csv(self.config.reviews_path)\n",
    "        dataset = dataset_reviews[[\"rating\", \"reviewContent\"]].copy()\n",
    "        dataset.dropna(inplace=True)\n",
    "        \n",
    "        logger.info(f\"Split reviews file to data train and test.\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            dataset[\"reviewContent\"], \n",
    "            dataset[\"rating\"], \n",
    "            test_size=self.config.params_test_size\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Dump data train into {self.config.input_train_path} directory.\")\n",
    "        X_train.to_pickle(self.config.input_train_path)\n",
    "        X_test.to_pickle(self.config.input_test_path)\n",
    "        \n",
    "        logger.info(f\"Dump data test into {self.config.input_test_path} directory.\")\n",
    "        y_train.to_pickle(self.config.output_train_path)\n",
    "        y_test.to_pickle(self.config.output_test_path)\n",
    "\n",
    "class Preprocessing:\n",
    "    def __init__(self, config: DataPreprocessingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def vectorize_data(self) -> None:\n",
    "        \"\"\"vectorize the splited dataset and dump vectorizer model\n",
    "        \"\"\"\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        \n",
    "        logger.info(f\"Load data train in {self.config.input_train_path}.\")\n",
    "        X_train = joblib.load(self.config.input_train_path)\n",
    "        \n",
    "        logger.info(f\"Load data test in {self.config.input_test_path}.\")\n",
    "        X_test = joblib.load(self.config.input_test_path)\n",
    "        \n",
    "        logger.info(f\"Vectorize the data.\")\n",
    "        X_train_vec = vectorizer.fit_transform(X_train)\n",
    "        X_test_vec = vectorizer.transform(X_test)\n",
    "        \n",
    "        logger.info(f\"Dump the vectorized data.\")\n",
    "        joblib.dump(X_train_vec, self.config.vectorized_train_path)\n",
    "        joblib.dump(X_test_vec, self.config.vectorized_test_path)\n",
    "        \n",
    "        logger.info(f\"Creating {self.config.model_dir} directory.\")\n",
    "        model_dir = str(self.config.model_dir)\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        logger.info(f\"Save the vectorizer model.\")\n",
    "        joblib.dump(vectorizer, self.config.vectorizer_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump the Data Train and Data Test\n",
    "\n",
    "This code in `src/LazadaIDReview/pipeline/step_02_preprocessing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-02 14:35:24,449: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-07-02 14:35:24,455: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2025-07-02 14:35:24,457: INFO: common: created directory at: artifacts]\n",
      "[2025-07-02 14:35:24,459: INFO: common: created directory at: artifacts/data]\n",
      "[2025-07-02 14:35:24,460: INFO: 821302001: Read reviews file.]\n",
      "[2025-07-02 14:35:25,657: INFO: 821302001: Split reviews file to data train and test.]\n",
      "[2025-07-02 14:35:25,673: INFO: 821302001: Dump data train into artifacts/data/X_train.pkl directory.]\n",
      "[2025-07-02 14:35:25,779: INFO: 821302001: Dump data test into artifacts/data/X_test.pkl directory.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    dump_data_config = config.get_dump_data_config()\n",
    "    data_ingestion = DumpData(config=dump_data_config)\n",
    "    data_ingestion.dump_data()\n",
    "except Exception as e:\n",
    "    logger.error(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debug**: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41910     murah namun berkualitas. sound juga ok. sayang...\n",
       "59760                         Packing rapih , produk sesuai\n",
       "64575                                                mantab\n",
       "11503                bagus, sesuai kebutuhan kerja, praktis\n",
       "43546                               barangnya blm di terima\n",
       "                                ...                        \n",
       "179467    barang sudah sampai dengan rapi, dan cepat,  t...\n",
       "17460     terima kasih barangnya udah sampai dan udah di...\n",
       "119535    Tolong balas gan, harganya seriusan tuh 48\" 1,...\n",
       "94170                         barangnya bagus n mantap..👍👍👍\n",
       "128584    cepat sekali datangnya, fd belum dicoba sih, s...\n",
       "Name: reviewContent, Length: 21405, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = joblib.load(dump_data_config.input_train_path)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41910     5\n",
       "59760     5\n",
       "64575     5\n",
       "11503     5\n",
       "43546     1\n",
       "         ..\n",
       "179467    3\n",
       "17460     4\n",
       "119535    5\n",
       "94170     5\n",
       "128584    5\n",
       "Name: rating, Length: 21405, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = joblib.load(dump_data_config.output_train_path)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191809    sdh 2 kali order TV coocaa di lazada, pertama ...\n",
       "203751           Barang sudah sampai ditempat,udah di pakai\n",
       "202508    Recomended bgt, barang cepat sampai dan sesuai...\n",
       "125832                   barang sesuai dengan pesanan trims\n",
       "26944                                 ori, pengiriman cepat\n",
       "                                ...                        \n",
       "16978     Barang bagus sesuai deskripsi, harga jg terjan...\n",
       "32392     Sangat amat kecewa hardisk tidak bisa terbaca ...\n",
       "719             pengririman cepat dan barang sesuai pesanan\n",
       "22690                   Paket dalam kondisi baik dan lancar\n",
       "4577                            spek maksimal harga minimal\n",
       "Name: reviewContent, Length: 85624, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = joblib.load(dump_data_config.input_test_path)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191809    5\n",
       "203751    5\n",
       "202508    5\n",
       "125832    5\n",
       "26944     5\n",
       "         ..\n",
       "16978     5\n",
       "32392     2\n",
       "719       5\n",
       "22690     5\n",
       "4577      5\n",
       "Name: rating, Length: 85624, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = joblib.load(dump_data_config.output_test_path)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the Data Train and Data Test\n",
    "\n",
    "This code in `src/LazadaIDReview/pipeline/step_02_preprocessing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-02 14:35:26,206: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-07-02 14:35:26,209: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2025-07-02 14:35:26,211: INFO: common: created directory at: artifacts]\n",
      "[2025-07-02 14:35:26,213: INFO: common: created directory at: artifacts/preprocessing]\n",
      "[2025-07-02 14:35:26,215: INFO: 821302001: Load data train in artifacts/data/X_train.pkl.]\n",
      "[2025-07-02 14:35:26,252: INFO: 821302001: Load data test in artifacts/data/X_test.pkl.]\n",
      "[2025-07-02 14:35:26,417: INFO: 821302001: Vectorize the data.]\n",
      "[2025-07-02 14:35:27,783: INFO: 821302001: Dump the vectorized data.]\n",
      "[2025-07-02 14:35:27,862: INFO: 821302001: Creating artifacts/models directory.]\n",
      "[2025-07-02 14:35:27,863: INFO: 821302001: Save the vectorizer model.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    preprocessing_config = config.get_preprocessing_data_config()\n",
    "    preprocessing = Preprocessing(config=preprocessing_config)\n",
    "    preprocessing.vectorize_data()\n",
    "except Exception as e:\n",
    "    logger.error(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debug**: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21405x13716 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 251565 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec = joblib.load(preprocessing_config.vectorized_train_path)\n",
    "X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<85624x13716 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 984159 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vec = joblib.load(preprocessing_config.vectorized_test_path)\n",
    "X_test_vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lazada-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
